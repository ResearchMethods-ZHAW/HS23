{
  "hash": "b80ff67cc91bbd7784dcf4ee4635b7d0",
  "result": {
    "markdown": "---\nexecute:\n  echo: true   # set to true to show musterlösung\n  output: true # set to true to show musterlösung\ncode-fold: true\ncode-summary: \"Musterlösung\"\nknitr:\n  opts_chunk: \n    collapse: true\n---\n\n\n# 5. Variablenselektion Multivariate Modelle / Habitatselektionsmodell\n\n## Libraries laden\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n\n## Funktion um Packages direkt zu installieren und / oder zu laden\n\nipak <- function(pkg){\n  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) \n    install.packages(new.pkg, dependencies = TRUE)\n  sapply(pkg, require, character.only = TRUE)\n}\n\npackages <- c(\"sp\", \"raster\", \"tidyverse\", \"PerformanceAnalytics\", \"pastecs\", \"lme4\", \n              \"bbmle\", \"MuMIn\", \"MASS\", \"magrittr\")\n\nipak(packages)\n##                   sp               raster            tidyverse \n##                 TRUE                 TRUE                 TRUE \n## PerformanceAnalytics              pastecs                 lme4 \n##                 TRUE                 TRUE                 TRUE \n##                bbmle                MuMIn                 MASS \n##                 TRUE                 TRUE                 TRUE \n##             magrittr \n##                 TRUE\n\nlibrary(\"sp\")\nlibrary(\"raster\")\nlibrary(\"tidyverse\")\nlibrary(\"PerformanceAnalytics\")\nlibrary(\"pastecs\")\nlibrary(\"lme4\")\nlibrary(\"bbmle\")\nlibrary(\"MuMIn\")\nlibrary(\"MASS\")\nlibrary(\"magrittr\")\n```\n:::\n\n\n## Variablenselektion\n**-> Vorgehen analog Coppes et al.**\n\n## Aufgabe 1\n\nMit dem folgenden Code kann eine simple Korrelationsmatrix aufgebaut werden. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n\nDF_mod <- read_delim(\"datasets/fallstudie_n/Aufgabe4_Datensatz_Habitatnutzung_Modelle_20221031_moodle.csv\", delim = \";\")\n\nDF_mod_day <- DF_mod |>\n  filter(time_of_day == \"day\")\n\n\nround(cor(DF_mod_day[,6:12], method = \"kendall\"),2)\n##                slope dist_road_all dist_road_only dist_build forest_prop    us\n## slope           1.00          0.13           0.16       0.11        0.18  0.22\n## dist_road_all   0.13          1.00           0.84       0.02       -0.08 -0.06\n## dist_road_only  0.16          0.84           1.00       0.03       -0.08 -0.04\n## dist_build      0.11          0.02           0.03       1.00        0.42  0.12\n## forest_prop     0.18         -0.08          -0.08       0.42        1.00  0.31\n## us              0.22         -0.06          -0.04       0.12        0.31  1.00\n## os              0.34         -0.06          -0.04       0.22        0.53  0.42\n##                   os\n## slope           0.34\n## dist_road_all  -0.06\n## dist_road_only -0.04\n## dist_build      0.22\n## forest_prop     0.53\n## us              0.42\n## os              1.00\n\n# hier kann die Schwelle für die Korrelation gesetzt werden, 0.7 ist liberal / \n# 0.5 konservativ\n\ncor <- round(cor(DF_mod_day[,6:12], method = \"kendall\"),2) \ncor[abs(cor)<0.7] <-0\ncor\n##                slope dist_road_all dist_road_only dist_build forest_prop us os\n## slope              1          0.00           0.00          0           0  0  0\n## dist_road_all      0          1.00           0.84          0           0  0  0\n## dist_road_only     0          0.84           1.00          0           0  0  0\n## dist_build         0          0.00           0.00          1           0  0  0\n## forest_prop        0          0.00           0.00          0           1  0  0\n## us                 0          0.00           0.00          0           0  1  0\n## os                 0          0.00           0.00          0           0  0  1\n```\n:::\n\n\n\n\n## Aufgabe 2\n\nSkalieren der Variablen, damit ihr Einfluss vergleichbar wird (Befehl scale(); Problem verschiedene Skalen der Variablen (bspw. Neigung in Grad, Distanz in Metern));\nUmwandeln der Reh-ID in einen Faktor, damit dieser als Random Factor ins Model eingespiesen werden kann.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n\nDF_mod_day %<>%\n  mutate(slope_scaled = scale(slope),\n         us_scaled = scale(us),\n         os_scaled = scale(os),\n         forest_prop_scaled = scale(forest_prop),\n         dist_road_all_scaled = scale(dist_road_all),\n         dist_road_only_scaled = scale(dist_road_only),\n         dist_build_scaled = scale(dist_build),\n         id = as.factor(id))\n```\n:::\n\n\n## Aufgabe 3\n\n**Selektion der Variablen in einem univariaten Model**\n\nEin erstes GLMM (Generalized Linear Mixed Effects Modell) aufbauen: Funktion und Modelformel\n\n> wichtige [Seite](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) auf der man viele Hilfestellungen zu GLMM’s finden kann.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n\n# wir werden das package lme4 mit der Funktion glmer verwenden \n\n# die Hilfe von glmer aufrufen: ?glmer\n\n# glmer(formula, data = , family = binomial)\n\n# 1) formula: \n# Abhängige Variable ~ Erklärende Variable + Random Factor \n# In unseren Modellen kontrollieren wir für individuelle Unterschiede bei den Rehen \n# indem wir einen Random Factor definieren => (1 | id) \n\n# 2) data: \n# euer Datensatz\n\n# 3) family: \n# hier binomial\n\n# warum binomial? Verteilung Daten der Abhängigen Variable Präsenz/Absenz \n\nggplot(DF_mod_day, aes(pres_abs)) + \n  geom_histogram()\n```\n\n::: {.cell-output-display}\n![](5_Variablenselektion_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\n\n# --> Binäre Verteilung => Binomiale Verteilung mit n = 1 \n\n# und wie schaut die Verteilung der Daten der Abhängigen Variable Nutzungsintensität \n# (nmb, werden wir in diesem Kurs aber nicht genauer anschauen) aus?\n```\n:::\n\n\n## Aufgabe 4\n\nMit der GLMM Formel bauen wir in einem ersten Schritt eine univariate Variablenselektion auf.\n\n***Als abhängige Variable verwenden wir die Präsenz/Absenz der Rehe in den Kreisen***\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Die erklärende Variable in m1 ist die erste Variable der korrelierenden Variablen\n# Die erklärende Variable in m2 ist die zweite Variable der korrelierenden Variablen\n\nm1 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 | id), data = DF_mod_day, \n            family = binomial)\nm2 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 | id), data = DF_mod_day, \n            family = binomial)\n\n# mit dieser Funktion können die Modellergebnisse inspiziert werden\nsummary(m1)\n\n# Mit dieser Funktion kann der Informationgehalt der beiden Modelle gegeneinander \n# abgeschätzt werden\nbbmle::AICtab(m1, m2)\n\n# tieferer AIC -> besser (AIC = Akaike information criterion)\n\n# ==> dieses Vorgehen muss nun für alle korrelierten Variablen für jeden Teildatensatz \n# (Tag/Nacht) durchgeführt werden, um nur noch nicht (R < 0.7) korrelierte Variablen \n# in das Modell einfliessen zu lassen \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- glmer(pres_abs ~ dist_road_all_scaled + (1 | id), data = DF_mod_day, family = binomial)\nm2 <- glmer(pres_abs ~ dist_road_only_scaled + (1 | id), data = DF_mod_day, family = binomial)\n\nsummary(m1)\n## Generalized linear mixed model fit by maximum likelihood (Laplace\n##   Approximation) [glmerMod]\n##  Family: binomial  ( logit )\n## Formula: pres_abs ~ dist_road_all_scaled + (1 | id)\n##    Data: DF_mod_day\n## \n##      AIC      BIC   logLik deviance df.resid \n##     5290     5309    -2642     5284     4182 \n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.2094 -0.7420 -0.6013  1.0727  2.0845 \n## \n## Random effects:\n##  Groups Name        Variance Std.Dev.\n##  id     (Intercept) 0.2216   0.4708  \n## Number of obs: 4185, groups:  id, 12\n## \n## Fixed effects:\n##                      Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)          -0.35871    0.14082  -2.547   0.0109 *  \n## dist_road_all_scaled  0.39252    0.03801  10.327   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## dst_rd_ll_s -0.010\n\nbbmle::AICtab(m1, m2)\n##    dAIC df\n## m2 0.0  3 \n## m1 5.3  3\n\n# tieferer AIC -> besser (AIC = Akaike information criterion) -> als deltaAIC\n# ausgewiesen besser == Distanz zu Strassen\n\n# ==> dieses Vorgehen muss nun für alle korrelierten Variablen für jeden\n# Teildatensatz (geringe Störung/starke Störung) durchgeführt werden, um nur\n# noch nicht (R < 0.7) korrelierte Variablen in das Modell einfliessen zu\n# lassen\n```\n:::\n\n\n## Aufgabe 5\n\n**Selektion der Variablen in einem multivariaten Model**\n\nMit folgendem Code kann eine automatisierte Variablenselektion (dredge-Funktion) und ein Modelaveraging aufgebaut werden (siehe auch Stats-Skript von J.Dengler & Team)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# hier wird die Formel für die dredge-Funktion vorbereitet (die Variablen V1-V6 \n# sind jene welche nach der univariaten Variablenselektion noch übrig bleiben)  \n\nf <- pres_abs ~ \n  V1 +\n  V2 +\n  V3 +\n  V4 +\n  V5 +\n  V6 \n\n# in diesem Befehl kommt der Random-Factor (das Reh) hinzu und es wird eine Formel \n# daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") |> as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch unbedingt ?dredge)\n\nall_m <- dredge(m)\n\n# Importance values der einzelnen Variablen (Gibt an, wie bedeutsam eine bestimmte \n# Variable ist, wenn man viele verschiedene Modelle vergleicht (multimodel inference))\n\nsw(all_m)\n\n# Schlussendlich wird ein Modelaverage durchgeführt (Schwellenwert für das delta-AIC = 2)\n\navgmodel <- model.avg(all_m, rank=\"AICc\", subset = delta < 2)\nsummary(avgmodel)\n\n# ==> für den Nachtdatensatz muss der gleiche Prozess der Variablenselektion \n# durchgespielt werden.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# hier wird die Formel für die dredge-Funktion vorbereitet (die Variablen V1-V6 \n# sind jene welche nach der univariaten Variablenselektion noch übrig bleiben)  \n\nf <- pres_abs ~ \n  slope_scaled +\n  us_scaled +\n  os_scaled +\n  forest_prop_scaled +\n  dist_road_only_scaled +\n  dist_build_scaled \n\n# inn diesem Befehl kommt der Random-Factor (das Reh) hinzu und es wird eine Formel \n# daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") %>% as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch unbedingt ?dredge)\n\nall_m <- dredge(m)\n\n# Importance values der einzelnen Variablen (Gibt an, wie bedeutsam eine bestimmte \n# Variable ist, wenn man viele verschiedene Modelle vergleicht (multimodel inference))\n\nsw(all_m)\n##                      dist_road_only_scaled forest_prop_scaled us_scaled\n## Sum of weights:      1.00                  1.00               1.00     \n## N containing models:   32                    32                 32     \n##                      slope_scaled dist_build_scaled os_scaled\n## Sum of weights:      0.95         0.67              0.39     \n## N containing models:   32           32                32\n\n\n# Schlussendlich wird ein Modelaverage durchgeführt (Schwellenwert für das delta-AIC = 2)\n\navgmodel <- model.avg(all_m, rank=\"AICc\", subset = delta < 2)\nsummary(avgmodel)\n## \n## Call:\n## model.avg(object = get.models(object = all_m, subset = delta < \n##     2), rank = \"AICc\")\n## \n## Component model call: \n## glmer(formula = pres_abs ~ <3 unique rhs>, data = DF_mod_day, family = \n##      binomial, na.action = na.fail)\n## \n## Component models: \n##        df   logLik    AICc delta weight\n## 12356   7 -2337.01 4688.05  0.00   0.48\n## 123456  8 -2336.48 4689.00  0.95   0.30\n## 2356    6 -2338.78 4689.58  1.53   0.22\n## \n## Term codes: \n##     dist_build_scaled dist_road_only_scaled    forest_prop_scaled \n##                     1                     2                     3 \n##             os_scaled          slope_scaled             us_scaled \n##                     4                     5                     6 \n## \n## Model-averaged coefficients:  \n## (full average) \n##                       Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n## (Intercept)           -0.49074    0.14774     0.14779   3.321 0.000898 ***\n## dist_build_scaled     -0.07877    0.06433     0.06434   1.224 0.220854    \n## dist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\n## forest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\n## slope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \n## us_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\n## os_scaled              0.01926    0.04529     0.04530   0.425 0.670605    \n##  \n## (conditional average) \n##                       Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n## (Intercept)           -0.49074    0.14774     0.14779   3.321 0.000898 ***\n## dist_build_scaled     -0.10139    0.05508     0.05510   1.840 0.065753 .  \n## dist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\n## forest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\n## slope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \n## us_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\n## os_scaled              0.06466    0.06284     0.06286   1.029 0.303635    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::",
    "supporting": [
      "5_Variablenselektion_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}