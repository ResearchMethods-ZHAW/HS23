{
  "hash": "ff2d26ed2a24f1b04d14cbae8e1fe099",
  "result": {
    "markdown": "---\ndate: 2023-11-20\nlesson: StatKons3\nthema: LM\nindex: 1\nformat:\n  html:\n    code-tools:\n      source: true\n---\n\n\n# StatKons3: Demo\n\n- Download dieses Demoscript via \"\\</\\>Code\" (oben rechts)\n\n\n\n\n\n## Einfaktorielle ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# für mehr infos\n# https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html\n\ncars <- mtcars |>\n  mutate(cyl = as.factor(cyl)) |>\n  slice(-31) # lösch die 31ste Zeile\n\n# Alternativ ginge auch das\ncars[-31, ]\n\n# schaue daten zuerst mal an\n# 1. Responsevariable\nhist(cars$hp) # nur sinnvoll bei grossem n\nboxplot(cars$hp)\n\n# 2. Responsevariable ~ Prediktorvariable\ntable(cars$cyl) # mögliches probel, da n's unterschiedlich gross\n\nboxplot(cars$hp ~ cars$cyl) # varianzheterogentität weniger das problem,\n# aber normalverteilung der residuen problematisch\n\n# definiere das modell für eine ein-faktorielle anova\naov.1 <- aov(log10(hp) ~ cyl, data = cars)\n\n# 3. Schaue Modelgüte an\npar(mfrow = c(2, 2))\nplot(aov.1)\n\n# 4. Schaue output an und ordne es ein\nsummary.lm(aov.1)\n\n# 5. bei meheren Kategorien wende einen post-hoc Vergleichstest an\nTukeyHSD(aov.1)\n\n# 6. Ergebnisse passend darstellen\nlibrary(\"multcomp\")\n\n# erstens die signifikanten Unterschiede mit Buchstaben versehen\nletters <- multcomp::cld(multcomp::glht(aov.1, linfct = multcomp::mcp(cyl = \"Tukey\"))) # Achtung die kategoriale\n# Variable (unsere unabhängige Variable \"cyl\") muss als Faktor\n# definiert sein z.B. as.factor()\n\n# einfachere Variante\nboxplot(hp ~ cyl, data = cars)\nmtext(letters$mcletters$Letters, at = 1:3)\n\n# schönere Variante :)\nggplot(cars, aes(x = cyl, y = hp)) +\n  stat_boxplot(geom = \"errorbar\", width = .5) +\n  geom_boxplot(size = 1) +\n  annotate(\"text\", x = 1, y = 350, label = \"a\", size = 7) +\n  annotate(\"text\", x = 2, y = 350, label = \"b\", size = 7) +\n  annotate(\"text\", x = 3, y = 350, label = \"c\", size = 7) +\n  labs(x = \"\\nAnzahl Zylinder\", y = \"Pferdestärke\") +\n  mytheme\n\n# Plot exportieren\nggsave(\n  filename = \"statKons/distill-preview.png\",\n  device = \"png\"\n) # hier kann man festlegen, was für ein Bildformat\n# exportiert werden möchte\n\n# Sind die Voraussetzungen für eine Anova verletzt, überprüfe alternative\n# nicht-parametische Tests z.B. oneway-Test mit Welch-korrektur für ungleiche\n# Varianzen (Achtung auch dieser Test hat Voraussetzungen -> siehe Skript XY)\nlibrary(\"rosetta\")\nwelch1 <- oneway.test(hp ~ cyl, data = cars, var.equal = FALSE)\nrosetta::posthocTGH(cars$hp, cars$cyl, method = \"games-howell\")\n```\n:::\n\n\n## Mehrfaktorielle ANOVA\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](StatKons3_Demo_LM_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```\n## \n## Call:\n## aov(formula = hp ~ cyl * am + wt, data = cars)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -33.834 -14.280  -7.418   7.120  60.282 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   32.743     31.636   1.035 0.310980    \n## cyl6          22.556     20.859   1.081 0.290274    \n## cyl8          88.818     20.463   4.340 0.000222 ***\n## am            13.002     19.952   0.652 0.520811    \n## wt            17.691      9.409   1.880 0.072272 .  \n## cyl6:am       14.626     27.392   0.534 0.598276    \n## cyl8:am       73.356     33.194   2.210 0.036894 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 26.73 on 24 degrees of freedom\n## Multiple R-squared:  0.8428,\tAdjusted R-squared:  0.8035 \n## F-statistic: 21.45 on 6 and 24 DF,  p-value: 1.511e-08\n```\n:::\n\n\n## Einfache Regression\n\n::: {.cell}\n\n```{.r .cell-code}\n# inspiriert von Simon Jackson: http s://drsimonj.svbtle.com/visualising-residuals\ncars <- mtcars |>\n  # ändere die unabhängige Variable mpg in 100Km/L\n  mutate(kml = (235.214583 / mpg)) # mehr Infos hier: https://www.asknumbers.com/mpg-to-L100km.aspx\n# |>  # klone data set\n# slice(-31) # # lösche Maserrati und schaue nochmals Modelfit an\n\n#############\n## 1.Daten anschauen\n############\n\n# Zusammenhang mal anschauen\n# Achtung kml = 100km pro Liter\nplot(hp ~ kml, data = cars)\n```\n\n::: {.cell-output-display}\n![](StatKons3_Demo_LM_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Responsevariable anschauen\nboxplot(cars$hp)\n```\n\n::: {.cell-output-display}\n![](StatKons3_Demo_LM_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Korrelationen uv + av anschauen\n# Reihenfolge spielt hier keine Rolle, wieso?\ncor(cars$kml, cars$hp) # hängen stark zusammen\n## [1] 0.7629477\n\n###################\n# 2. Modell definieren: einfache regression\n##################\nmodel <- lm(hp ~ kml, data = cars)\nsummary.lm(model)\n## \n## Call:\n## lm(formula = hp ~ kml, data = cars)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -75.22 -25.52 -13.31  30.92 148.69 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  -26.021     27.880  -0.933    0.358    \n## kml           13.540      2.095   6.464 3.84e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 45.06 on 30 degrees of freedom\n## Multiple R-squared:  0.5821,\tAdjusted R-squared:  0.5682 \n## F-statistic: 41.79 on 1 and 30 DF,  p-value: 3.839e-07\n\n###############\n# 3.Modeldiagnostik und ggf. Anpassungen ans Modell oder ähnliches\n###############\n\n# semi schöne Ergebnisse\nlibrary(\"ggfortify\")\n## Error in library(\"ggfortify\"): there is no package called 'ggfortify'\nggplot2::autoplot(model) + mytheme # gitb einige Extremwerte => was tun? (Eingabe/Einlesen\n## Error in `ggplot2::autoplot()`:\n## ! Objects of class <lm> are not supported by autoplot.\n## ℹ have you loaded the required package?\n# überprüfen, Transformation, Extremwerte nur ausschliessen mit guter Begründung)\n\n# erzeuge vorhergesagte Werte und Residualwerte\ncars$predicted <- predict(model) # bilde neue Variable mit geschätzten y-Werten\ncars$residuals <- residuals(model)\n\n# schaue es dir an, sieht man gut was die Residuen sind\nd <- cars |>\n  dplyr::select(hp, kml, predicted, residuals)\n\n# schauen wir es uns an\nhead(d, 4)\n##                 hp      kml predicted residuals\n## Mazda RX4      110 11.20069  125.6411 -15.64107\n## Mazda RX4 Wag  110 11.20069  125.6411 -15.64107\n## Datsun 710      93 10.31643  113.6678 -20.66776\n## Hornet 4 Drive 110 10.99134  122.8063 -12.80626\n\n# visualisiere residuen\nggplot(d, aes(x = kml, y = hp)) +\n  # verbinde beobachtete werte mit vorausgesagte werte\n  geom_segment(aes(xend = kml, yend = predicted)) +\n  geom_point() + # Plot the actual points\n  geom_point(aes(y = predicted), shape = 4) + # plot geschätzten y-Werten\n  # geom_line(aes(y = predicted), color = \"lightgrey\") # alternativ code\n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +\n  # Farbe wird hier zu den redisuen gemapped, abs(residuals) wegen negativen zahlen\n  geom_point(aes(color = abs(residuals))) +\n  # Colors to use here (für mehrere farben verwende color_gradient2)\n  scale_color_continuous(low = \"blue\", high = \"red\") +\n  scale_x_continuous(limits = c(0, 40)) +\n  scale_y_continuous(limits = c(0, 300)) +\n  guides(color = \"none\") + # Color legende entfernen\n  labs(x = \"\\nVerbraucht in Liter pro 100km\", y = \"Motorleistung in PS\\n\") +\n  mytheme\n```\n\n::: {.cell-output-display}\n![](StatKons3_Demo_LM_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\n\n##########\n# 4. plotte Ergebnis\n##########\nggplot(d, aes(x = kml, y = hp)) +\n  geom_point(size = 4) +\n  # geom_point(aes(y = predicted), shape = 1, size = 4) +\n  # plot regression line\n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +\n  # intercept\n  geom_line(aes(y = mean(hp)), color = \"blue\") +\n  mytheme\n```\n\n::: {.cell-output-display}\n![](StatKons3_Demo_LM_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n:::\n\n\n## Multiple Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data\ncars <- mtcars |>\n  slice(-31) |>\n  mutate(kml = (235.214583 / mpg)) |>\n  dplyr::select(kml, hp, wt, disp)\n\n################\n# 1. Multikollinearitüt überprüfen\n# Korrelation zwischen Prädiktoren kleiner .7\ncor <- cor(cars[, -2])\ncor[abs(cor) < 0.7] <- 0\ncor #\n##            kml        wt      disp\n## kml  1.0000000 0.8912658 0.8786238\n## wt   0.8912658 1.0000000 0.8878515\n## disp 0.8786238 0.8878515 1.0000000\n\n##### info zu Variablen\n# wt = gewicht\n# disp = hubraum\n\n###############\n# 2. Responsevariable + Kriteriumsvariable anschauen\n##############\n# was würdet ihr tun?\n\n############\n# 3. Definiere das Model\n############\nmodel1 <- lm(hp ~ kml + wt + disp, data = cars)\nmodel2 <- lm(hp ~ kml + wt, data = cars)\nmodel3 <- lm(log10(hp) ~ kml + wt, data = cars)\n\n#############\n# 4. Modeldiagnostik\n############\n\nggplot2::autoplot(model1)\n## Error in `ggplot2::autoplot()`:\n## ! Objects of class <lm> are not supported by autoplot.\n## ℹ have you loaded the required package?\nggplot2::autoplot(model2) # besser, immernoch nicht ok => transformation? vgl. model3\n## Error in `ggplot2::autoplot()`:\n## ! Objects of class <lm> are not supported by autoplot.\n## ℹ have you loaded the required package?\nggplot2::autoplot(model3)\n## Error in `ggplot2::autoplot()`:\n## ! Objects of class <lm> are not supported by autoplot.\n## ℹ have you loaded the required package?\n\n############\n# 5. Modellfit vorhersagen: wie gut sagt mein Modell meine Daten vorher\n############\n\n# es gibt 3 Mögliche Wege\n\n# gebe dir predicted values aus für model2 (für vorzeigebeispiel einfacher :)\n# gibts unterschidliche varianten die predicted values zu berechnen\n# 1. default funktion predict(model) verwenden\ncars$predicted <- predict(model2)\n\n# 2. datensatz selber zusammenstellen (nicht empfohlen): wichtig, die\n# prädiktoren müssen denselben\n# namen haben wie im Model\n# besser mit Traindata von Beginn an mehr Infos hier: https://www.r-bloggers.com/using-linear-regression-to-predict-energy-output-of-a-power-plant/\n\nnew.data <- tibble(\n  kml = sample(seq(6.9384, 22.61, .3), 31),\n  wt = sample(seq(1.513, 5.424, 0.01), 31),\n  disp = sample(seq(71.1, 472.0, .1), 31)\n)\ncars$predicted_own <- predict(model2, newdata = new.data)\n\n# 3. train_test_split durchführen (empfohlen) muss jedoch von beginn an bereits\n# gemacht werden - Logik findet ihr hier: https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 oder https://towardsdatascience.com/6-amateur-mistakes-ive-made-working-with-train-test-splits-916fabb421bb\n# beispiel hier: https://ijlyttle.github.io/model_cv_selection.html\ncars <- mtcars |>\n  mutate(id = row_number()) |> # für das mergen der Datensätze\n  mutate(kml = (235.214583 / mpg)) |>\n  dplyr::select(kml, hp, wt, disp, id)\n\ntrain_data <- cars |>\n  dplyr::sample_frac(.75) # für das Modellfitting\n\ntest_data <- dplyr::anti_join(cars, train_data, by = \"id\") # für den Test mit predict\n\n# erstelle das Modell und \"trainiere\" es auf den train Datensatz\nmodel2_train <- lm(hp ~ kml + wt, data = train_data)\n\n# mit dem \"neuen\" Datensatz wird das Model überprüft ob guter Modelfit\ntrain_data$predicted_test <- predict(model2_train, newdata = test_data)\n\n# Residuen\ntrain_data$residuals <- residuals(model2_train)\nhead(train_data)\n##                          kml  hp    wt  disp id predicted_test  residuals\n## Fiat 128            7.259709  66 2.200  78.7 18       121.2821  -6.350549\n## Dodge Challenger   15.175134 150 3.520 318.0 22       142.8229 -29.090167\n## Lotus Europa        7.737322 113 1.513  95.1 28       112.0127  31.496205\n## Cadillac Fleetwood 22.616787 205 5.250 472.0 15       138.2124 -72.710696\n## Pontiac Firebird   12.250760 175 3.845 400.0 25       183.6065  38.220571\n## Valiant            12.995281 105 3.460 225.0  6       213.2888 -43.620868\n\n# weiterführende Infos zu \"machine learning\" Idee hier: https://stat-ata-asu.github.io/MachineLearningToolbox/regression-models-fitting-them-and-evaluating-their-performance.html\n# wichtigstes Packet in dieser Hinsicht ist \"caret\": https://topepo.github.io/caret/\n# beste Philosophie ist tidymodels: https://www.tidymodels.org\n\n#----------------\n# Schnelle variante mit broom\nd <- lm(hp ~ kml + wt + disp, data = cars) |>\n  broom::augment()\n\nhead(d)\n## # A tibble: 6 × 11\n##   .rownames            hp   kml    wt  disp .fitted .resid   .hat .sigma .cooksd\n##   <chr>             <dbl> <dbl> <dbl> <dbl>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n## 1 Mazda RX4           110  11.2  2.62   160    123. -12.7  0.0478   41.4 1.29e-3\n## 2 Mazda RX4 Wag       110  11.2  2.88   160    114.  -4.21 0.0456   41.4 1.34e-4\n## 3 Datsun 710           93  10.3  2.32   108    103.  -9.87 0.0758   41.4 1.31e-3\n## 4 Hornet 4 Drive      110  11.0  3.22   258    142. -31.6  0.0958   41.0 1.77e-2\n## 5 Hornet Sportabout   175  12.6  3.44   360    191. -16.3  0.210    41.3 1.35e-2\n## 6 Valiant             105  13.0  3.46   225    138. -33.5  0.0445   40.9 8.22e-3\n## # ℹ 1 more variable: .std.resid <dbl>\n\nggplot(d, aes(x = kml, y = hp)) +\n  geom_segment(aes(xend = kml, yend = .fitted), alpha = .2) +\n  geom_point(aes(color = .resid)) +\n  scale_color_gradient2(low = \"blue\", mid = \"white\", high = \"red\") +\n  guides(color = \"none\") +\n  geom_point(aes(y = .fitted), shape = 4) +\n  scale_y_continuous(limits = c(0, 350)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +\n  mytheme\n```\n\n::: {.cell-output-display}\n![](StatKons3_Demo_LM_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n############\n# 6. Modellvereinfachung\n############\n\n# Varianzpartitionierung\nlibrary(\"hier.part\")\n## Error in library(\"hier.part\"): there is no package called 'hier.part'\ncars <- mtcars |>\n  mutate(kml = (235.214583 / mpg)) |>\n  select(-mpg)\n\nnames(cars) # finde \"position\" deiner Responsevariable\n##  [1] \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\" \"carb\"\n## [11] \"kml\"\n\nX = cars[, -3] # definiere all die Prädiktorvariablen im Model (minus Responsevar)\n\n# dauert ein paar sekunden\nhier.part(cars$hp, X, gof = \"Rsqu\")\n## Error in hier.part(cars$hp, X, gof = \"Rsqu\"): could not find function \"hier.part\"\n\n# alle Modelle miteinander vergleichen mit dredge Befehl: geht nur bis\n# maximal 15 Variablen\nmodel2 <- lm(hp ~ ., data = cars)\nlibrary(\"MuMIn\")\n## Error in library(\"MuMIn\"): there is no package called 'MuMIn'\noptions(na.action = \"na.fail\")\nallmodels <- dredge(model2)\n## Error in dredge(model2): could not find function \"dredge\"\nhead(allmodels)\n## Error in eval(expr, envir, enclos): object 'allmodels' not found\n\n# Wichtigkeit der Prädiktoren\nMuMIn::importance(allmodels)\n## Error in loadNamespace(x): there is no package called 'MuMIn'\n\n# mittleres Model\navgmodel <- MuMIn::model.avg(get.models(allmodels, subset = TRUE))\n## Error in loadNamespace(x): there is no package called 'MuMIn'\nsummary(avgmodel)\n## Error in eval(expr, envir, enclos): object 'avgmodel' not found\n\n# adäquatest model gemäss multimodel inference\nmodel_ad <- lm(hp ~ carb + disp + wt, data = mtcars)\nsummary(model_ad)\n## \n## Call:\n## lm(formula = hp ~ carb + disp + wt, data = mtcars)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -45.225 -14.235   3.879  20.621  39.785 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  53.16715   18.16036   2.928  0.00671 ** \n## carb         23.57691    2.99391   7.875 1.41e-08 ***\n## disp          0.51663    0.07669   6.736 2.59e-07 ***\n## wt          -28.59214    9.87292  -2.896  0.00725 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 24.32 on 28 degrees of freedom\n## Multiple R-squared:  0.8863,\tAdjusted R-squared:  0.8742 \n## F-statistic: 72.78 on 3 and 28 DF,  p-value: 2.462e-13\n```\n:::\n",
    "supporting": [
      "StatKons3_Demo_LM_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}