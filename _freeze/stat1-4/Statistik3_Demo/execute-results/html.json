{
  "hash": "82b81d1b7b6df3562f1865566b238d7f",
  "result": {
    "markdown": "---\ndate: 2023-11-06\nlesson: Stat3\nthema: Lineare Modelle II\nindex: 1\nformat:\n  html:\n    code-tools:\n      source: true\n---\n\n\n# Stat3: Demo\n\n-   Download dieses Demoscript via \"\\</\\>Code\" (oben rechts)\n-   Datensatz *ipomopsis.csv*\n-   Datensatz *loyn.csv*\n\n## ANCOVA\n\nExperiment zur Fruchtproduktion (\"Fruit\") von Ipomopsis sp. (\"Fruit\") in Abhängigkeit von der Beweidung (\"Grazing\" mit 2 Levels: \"Grazed\", \"Ungrazed\") und korrigiert für die Pflanzengrösse vor der Beweidung (hier ausgedrückt als Durchmesser an der Spitze des Wurzelstock: \"Root\")\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Daten einlesen und anschauen\n\ncompensation <- read.delim(\"datasets/stat1-4/ipomopsis.csv\", sep = \",\", stringsAsFactors = T)\n## Error in file(file, \"rt\"): cannot open the connection\nhead(compensation)\n## Error in eval(expr, envir, enclos): object 'compensation' not found\nsummary(compensation)\n## Error in eval(expr, envir, enclos): object 'compensation' not found\n\n# Pflanzengrösse (\"Root\") vs. Fruchtproduktion (\"Fruit\")\nplot(Fruit ~ Root, data = compensation)\n## Error in eval(m$data, eframe): object 'compensation' not found\n```\n:::\n\n\n-> Je grösser die Pflanze, desto grösser ihre Fruchtproduktion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Beweidung (\"Grazing\") vs. Fruchtroduktion (\"Fruit)\nboxplot(Fruit ~ Grazing, data = compensation)\n## Error in eval(m$data, parent.frame()): object 'compensation' not found\n```\n:::\n\n\n-> In der beweideten Gruppe scheint die Fruchtproduktion grösser. Liegt dies an der Beweidung oder an unterschiedlichen Pflanzengrössen zwischen den Gruppen?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plotten der vollständigen Daten/Information\nlibrary(\"ggplot2\")\nggplot(compensation, aes(Root, Fruit, color = Grazing)) +\n  geom_point() +\n  theme_classic()\n## Error in eval(expr, envir, enclos): object 'compensation' not found\n```\n:::\n\n\n-> Die grössere Fruchtproduktion innerhalb der beweideten Gruppe scheint also ein Resultat von unterschiedlichen Pflanzengrössen zwischen den Gruppen zu sein und nicht an der Beweidung zu liegen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Lineare Modelle definieren und anschauen\n\naoc.1 <- lm(Fruit ~ Root * Grazing, data = compensation) # Volles Modell mit Interaktion\n## Error in eval(mf, parent.frame()): object 'compensation' not found\nsummary.aov(aoc.1)\n## Error in eval(expr, envir, enclos): object 'aoc.1' not found\n\naoc.2 <- lm(Fruit ~ Grazing + Root, data = compensation) # Finales Modell ohne die (nicht signifikante Interaktion)\n## Error in eval(mf, parent.frame()): object 'compensation' not found\nsummary.aov(aoc.2) # ANOVA-Tabelle\n## Error in eval(expr, envir, enclos): object 'aoc.2' not found\nsummary(aoc.2) # Parameter-Tabelle\n## Error in eval(expr, envir, enclos): object 'aoc.2' not found\n\n# Residualplots anschauen\npar(mfrow = c(2, 2))\nplot(aoc.2)\n## Error in eval(expr, envir, enclos): object 'aoc.2' not found\n```\n:::\n\n\n-> Das ANCOVA-Modell widerspiegelt die Zusammenhänge wie sie aufgrund der grafisch dargestellten Daten zu vermuten sind gut. Die Residual-Plots zeigen 3 Ausreisser (Beobachtungen 27, 34 und 37), welche \"aus der Reihe tanzen\".\n\n## Polynomische Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Daten generieren und Modelle rechnen\npred <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24) # \"pred\" sei unsere unabhängige Variable\nresp <- c(12, 15, 10, 7, 2, 10, 12, 11, 13, 10, 9, 2, 4, 7, 13) # \"resp\" sei unsere abhängige Variable\n\nplot(pred, resp) # So sehen die Daten aus\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Modelle definieren\nlm.1 <- lm(resp ~ pred) # Einfaches lineares Modell\nlm.quad <- lm(resp ~ pred + I(pred^2)) # lineares Modell mit quadratischem Term\n\nsummary(lm.1) # Modell anschauen\n## \n## Call:\n## lm(formula = resp ~ pred)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -9.0549 -1.7015  0.5654  2.0617  5.6406 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  12.2879     2.4472   5.021 0.000234 ***\n## pred         -0.1541     0.1092  -1.412 0.181538    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.863 on 13 degrees of freedom\n## Multiple R-squared:  0.1329,\tAdjusted R-squared:  0.06622 \n## F-statistic: 1.993 on 1 and 13 DF,  p-value: 0.1815\n```\n:::\n\n\n-> kein signifikanter Zusammenhang und entsprechend kleines Bestimmtheitsmass (adj. R^2^ = 0.07)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm.quad) # Modell anschauen\n## \n## Call:\n## lm(formula = resp ~ pred + I(pred^2))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4.3866 -1.1018 -0.2027  1.3831  4.4211 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)   \n## (Intercept) -2.239308   3.811746  -0.587  0.56777   \n## pred         1.330933   0.360105   3.696  0.00306 **\n## I(pred^2)   -0.031587   0.007504  -4.209  0.00121 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.555 on 12 degrees of freedom\n## Multiple R-squared:  0.6499,\tAdjusted R-squared:  0.5915 \n## F-statistic: 11.14 on 2 and 12 DF,  p-value: 0.001842\n```\n:::\n\n\n-> signifikanter Zusammenhang und viel besseres Bestimmtheitsmass (adj. R^2^ = 0.60)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelle plotten\n\npar(mfrow = c(1, 2))\n\n# 1. lineares Modell\nplot(resp ~ pred, main = \"Lineares Modell\")\nabline(lm.1, col = \"blue\")\n\n# 2. quadratisches Modell\nplot(resp ~ pred, main = \"Quadratisches  Modell\")\nxv <- seq(0, 40, 0.1) # Input für Modellvoraussage via predict ()\nyv2 <- predict(lm.quad, list(pred = xv))\nlines(xv, yv2, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Residualplots\npar(mfrow = c(2, 2))\nplot(lm.1, main = \"Lineares Modell\")\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm.quad, main = \"Quadratisches  Modell\")\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\n### Simulation Overfitting\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Beispieldaten mit 6 Datenpunkten\ntest <- data.frame(\"x\" = c(1, 2, 3, 4, 5, 6), \"y\" = c(34, 21, 70, 47, 23, 45))\n\npar(mfrow = c(1, 1))\nplot(y ~ x, data = test)\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Zunehmend komplizierte Modelle (je komplizierter desto overfitteter) definieren\nlm.0 <- lm(y ~ 1, data = test)\nlm.1 <- lm(y ~ x, data = test)\nlm.2 <- lm(y ~ x + I(x^2), data = test)\nlm.3 <- lm(y ~ x + I(x^2) + I(x^3), data = test)\nlm.4 <- lm(y ~ x + I(x^2) + I(x^3) + I(x^4), data = test)\nlm.5 <- lm(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5), data = test)\n\n# Summaries rechnen\nsmy.0 <- summary(lm.0)\nsmy.1 <- summary(lm.1)\nsmy.2 <- summary(lm.2)\nsmy.3 <- summary(lm.3)\nsmy.4 <- summary(lm.4)\nsmy.5 <- summary(lm.5)\n\n# R2 vergleichen\n\nsmy.0$r.squared\n## [1] 0\nsmy.1$r.squared\n## [1] 0.01242685\nsmy.2$r.squared\n## [1] 0.1105981\nsmy.3$r.squared\n## [1] 0.1697982\nsmy.4$r.squared\n## [1] 0.874639\nsmy.5$r.squared\n## [1] 1\nsmy.5$adj.r.squared\n## [1] NaN\n```\n:::\n\n\n-> R2 wird immer grösser, d.h. die Modelle werden immer besser. ;-)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelle plotten\nxv <- seq(from = 0, to = 10, by = 0.1)\nplot(y ~ x, cex = 2, col = \"black\", lwd = 3, data = test)\nyv <- predict(lm.1, list(x = xv))\nlines(xv, yv, col = \"red\", lwd = 3)\ntext(x = c(1, 70), \"lm.1\", col = \"red\")\nyv <- predict(lm.2, list(x = xv))\nlines(xv, yv, col = \"blue\", lwd = 3)\ntext(x = c(1, 65), \"lm.2\", col = \"blue\")\nyv <- predict(lm.3, list(x = xv))\nlines(xv, yv, col = \"green\", lwd = 3)\ntext(x = c(1, 60), \"lm.3\", col = \"green\")\nyv <- predict(lm.4, list(x = xv))\nlines(xv, yv, col = \"orange\", lwd = 3)\ntext(x = c(1, 55), \"lm.4\", col = \"orange\")\nyv <- predict(lm.5, list(x = xv))\nlines(xv, yv, col = \"violet\", lwd = 3)\ntext(x = c(1, 50), \"lm.5\", col = \"violet\")\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n-> Auch der optische Fit wird immer besser. Wir bestreiben jedoch Overfitting und Overfittig ist nicht gut: Denn, macht es Sinn, 6 Datenpunkte mit einem Modell mit 6 Parametern zu fitten??\n\n## Multiple lineare Regression (basierend auf Logan, Beispiel 9A)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Daten laden und anschauen\nloyn <- read.delim(\"datasets/stat1-4/loyn.csv\", sep = \",\")\n## Error in file(file, \"rt\"): cannot open the connection\nsummary(loyn)\n## Error in eval(expr, envir, enclos): object 'loyn' not found\n```\n:::\n\n\n### Korrelation zwischen den Prädiktoren\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wir setzen die Schwelle bei |0.7|\n\ncor <- cor(loyn[, 3:8]) # Korrelationen rechnen details siehe: \"?cor\"\n## Error in eval(expr, envir, enclos): object 'loyn' not found\n\n# Korrelationen Visualisieren (google: \"correlation plot r\"...)\nlibrary(\"corrplot\")\n## Error in library(\"corrplot\"): there is no package called 'corrplot'\n\ncorrplot.mixed(cor, lower = \"ellipse\", upper = \"number\", order = \"AOE\")\n## Error in corrplot.mixed(cor, lower = \"ellipse\", upper = \"number\", order = \"AOE\"): could not find function \"corrplot.mixed\"\n```\n:::\n\n\n-> Keine Korrelation ist \\>\\|0.7\\| . Aber es gilt zu beachten , dass GRAZE ziemlich stark \\|\\>0.6\\| mit YR.ISOL korreliert ist\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Volles Modell definieren\n\nnames(loyn)\n## Error in eval(expr, envir, enclos): object 'loyn' not found\nlm.1 <- lm(ABUND ~ YR.ISOL + AREA + DIST + LDIST + GRAZE + ALT, data = loyn)\n## Error in eval(mf, parent.frame()): object 'loyn' not found\n\nlibrary(\"car\")\n## Error in library(\"car\"): there is no package called 'car'\n\npar(mfrow = c(2, 2))\nplot(lm.1)\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n-> Plot sieht zwar ok aus, aber mit 6 Prädiktoren ist das Modell wohl \"overfitted\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(lm.1)\n## Error in vif(lm.1): could not find function \"vif\"\n```\n:::\n\n\n### Modellvereinfachung\n\nSchrittweise die am wenigsten signifkanten Terme entfernen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.1 <- lm(ABUND ~ YR.ISOL + AREA + DIST + LDIST + GRAZE + ALT, data = loyn)\n## Error in eval(mf, parent.frame()): object 'loyn' not found\nsummary(lm.1)\n## \n## Call:\n## lm(formula = y ~ x, data = test)\n## \n## Residuals:\n##       1       2       3       4       5       6 \n##  -3.286 -17.371  30.543   6.457 -18.629   2.286 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)\n## (Intercept)   36.200     18.847   1.921    0.127\n## x              1.086      4.839   0.224    0.833\n## \n## Residual standard error: 20.24 on 4 degrees of freedom\n## Multiple R-squared:  0.01243,\tAdjusted R-squared:  -0.2345 \n## F-statistic: 0.05033 on 1 and 4 DF,  p-value: 0.8335\n\nlm.2 <- update(lm.1, ~ . - AREA) # Prädiktor mit grösstem p-Wert entfernen\nanova(lm.1, lm.2) # Modelle vergleichen (falls signifikant, so müssten man den Prädiktor wieder ins Modell nehmen)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x\n##   Res.Df    RSS Df Sum of Sq F Pr(>F)\n## 1      4 1639.4                      \n## 2      4 1639.4  0         0\nsummary(lm.2) # Neues einfacheres Modell anschauen und Prädiktor mit grösstem p-Wert ausfindig machen\n## \n## Call:\n## lm(formula = y ~ x, data = test)\n## \n## Residuals:\n##       1       2       3       4       5       6 \n##  -3.286 -17.371  30.543   6.457 -18.629   2.286 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)\n## (Intercept)   36.200     18.847   1.921    0.127\n## x              1.086      4.839   0.224    0.833\n## \n## Residual standard error: 20.24 on 4 degrees of freedom\n## Multiple R-squared:  0.01243,\tAdjusted R-squared:  -0.2345 \n## F-statistic: 0.05033 on 1 and 4 DF,  p-value: 0.8335\n\n# Oben beschriebene Schritte wiederholen bis nur noch signifikante Prädiktoren im Modell\nlm.3 <- update(lm.2, ~ . - DIST)\nanova(lm.2, lm.3)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x\n##   Res.Df    RSS Df Sum of Sq F Pr(>F)\n## 1      4 1639.4                      \n## 2      4 1639.4  0         0\nsummary(lm.3)\n## \n## Call:\n## lm(formula = y ~ x, data = test)\n## \n## Residuals:\n##       1       2       3       4       5       6 \n##  -3.286 -17.371  30.543   6.457 -18.629   2.286 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)\n## (Intercept)   36.200     18.847   1.921    0.127\n## x              1.086      4.839   0.224    0.833\n## \n## Residual standard error: 20.24 on 4 degrees of freedom\n## Multiple R-squared:  0.01243,\tAdjusted R-squared:  -0.2345 \n## F-statistic: 0.05033 on 1 and 4 DF,  p-value: 0.8335\n\nlm.4 <- update(lm.3, ~ . - YR.ISOL)\nanova(lm.3, lm.4)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x\n##   Res.Df    RSS Df Sum of Sq F Pr(>F)\n## 1      4 1639.4                      \n## 2      4 1639.4  0         0\nsummary(lm.4)\n## \n## Call:\n## lm(formula = y ~ x, data = test)\n## \n## Residuals:\n##       1       2       3       4       5       6 \n##  -3.286 -17.371  30.543   6.457 -18.629   2.286 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)\n## (Intercept)   36.200     18.847   1.921    0.127\n## x              1.086      4.839   0.224    0.833\n## \n## Residual standard error: 20.24 on 4 degrees of freedom\n## Multiple R-squared:  0.01243,\tAdjusted R-squared:  -0.2345 \n## F-statistic: 0.05033 on 1 and 4 DF,  p-value: 0.8335\n\nlm.5 <- update(lm.4, ~ . - LDIST)\nanova(lm.4, lm.5)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x\n##   Res.Df    RSS Df Sum of Sq F Pr(>F)\n## 1      4 1639.4                      \n## 2      4 1639.4  0         0\nsummary(lm.5)\n## \n## Call:\n## lm(formula = y ~ x, data = test)\n## \n## Residuals:\n##       1       2       3       4       5       6 \n##  -3.286 -17.371  30.543   6.457 -18.629   2.286 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)\n## (Intercept)   36.200     18.847   1.921    0.127\n## x              1.086      4.839   0.224    0.833\n## \n## Residual standard error: 20.24 on 4 degrees of freedom\n## Multiple R-squared:  0.01243,\tAdjusted R-squared:  -0.2345 \n## F-statistic: 0.05033 on 1 and 4 DF,  p-value: 0.8335\n\nlm.6 <- update(lm.5, ~ . - ALT)\nanova(lm.5, lm.6)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x\n##   Res.Df    RSS Df Sum of Sq F Pr(>F)\n## 1      4 1639.4                      \n## 2      4 1639.4  0         0\nsummary(lm.6)\n## \n## Call:\n## lm(formula = y ~ x, data = test)\n## \n## Residuals:\n##       1       2       3       4       5       6 \n##  -3.286 -17.371  30.543   6.457 -18.629   2.286 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)\n## (Intercept)   36.200     18.847   1.921    0.127\n## x              1.086      4.839   0.224    0.833\n## \n## Residual standard error: 20.24 on 4 degrees of freedom\n## Multiple R-squared:  0.01243,\tAdjusted R-squared:  -0.2345 \n## F-statistic: 0.05033 on 1 and 4 DF,  p-value: 0.8335\n\npar(mfrow = c(2, 2))\nplot(lm.6)\n```\n\n::: {.cell-output-display}\n![](Statistik3_Demo_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n-> das minimal adäquate Modell enthält nur noch einen Prädiktor (GRAZE) und dessen Residualplots sehen ok aus.\n\n### Hierarchical partitioning\n\nWir können auch schauen wie bedeutsam die einzelnen Variablen sind:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"hier.part\")\n## Error in library(\"hier.part\"): there is no package called 'hier.part'\n\nloyn.preds <- with(loyn, data.frame(YR.ISOL, AREA, DIST, LDIST, GRAZE, ALT))\n## Error in eval(expr, envir, enclos): object 'loyn' not found\n\npar(mfrow = c(1, 1))\nhier.part(loyn$ABUND, loyn.preds, gof = \"Rsqu\")\n## Error in hier.part(loyn$ABUND, loyn.preds, gof = \"Rsqu\"): could not find function \"hier.part\"\n```\n:::\n\n\n-> auch hier sticht GRAZE heraus. (und an zweiter Stelle YR.ISOL, der mit GRAZE am stärksten korreliert ist)\n\n### Partial regressions\n\n\n::: {.cell}\n\n```{.r .cell-code}\navPlots(lm.1, ask = F)\n## Error in avPlots(lm.1, ask = F): could not find function \"avPlots\"\n```\n:::\n\n\n## Multimodel inference\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"MuMIn\")\n## Error in library(\"MuMIn\"): there is no package called 'MuMIn'\n\nglobal.model <- lm(ABUND ~ YR.ISOL + AREA +  DIST + LDIST + GRAZE + ALT, data = loyn)\n## Error in eval(mf, parent.frame()): object 'loyn' not found\n\noptions(na.action = \"na.fail\")\n\nallmodels <- dredge(global.model)\n## Error in dredge(global.model): could not find function \"dredge\"\nallmodels\n## Error in eval(expr, envir, enclos): object 'allmodels' not found\n\n# Variable importance\nsw(allmodels)\n## Error in sw(allmodels): could not find function \"sw\"\n```\n:::\n\n\n-> Auch mit dieser Sichtweise ist GRAZE der wichtigste Prädiktor\n\n\n::: {.cell}\n\n```{.r .cell-code}\navgmodel <- model.avg(allmodels, subset = TRUE)\n## Error in model.avg(allmodels, subset = TRUE): could not find function \"model.avg\"\nsummary(avgmodel)\n## Error in eval(expr, envir, enclos): object 'avgmodel' not found\n```\n:::\n",
    "supporting": [
      "Statistik3_Demo_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}