{
  "hash": "850a0e3d2132a3ead8a7a75edbc23a34",
  "result": {
    "markdown": "---\ndate: 2023-11-07\nlesson: Stat4\nthema: Komplexere Regressionsmethoden\nindex: 4\nformat:\n  html:\n    code-tools:\n      source: true\n---\n\n\n# Stat4: Lösung 4.2S\n\n- Download dieses Lösungsscript via \"\\</\\>Code\" (oben rechts)\n\n## Musterlösung Übung 4.2S: Multiple logistische Regression (SozWis)\n\n- **Lese-Empfehlung** Kapitel 6 von [Manny Gimond]( https://mgimond.github.io/Stats-in-R/Logistic.html)\n- **Lese-Empfehlung** Kapitel 4 von [Gareth (2016)](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n- **Lese-Empfehlung** Vorlesungsfolien von Oscar Torres-Reyna [Princeton University](https://www.princeton.edu/~otorres/LogitR101.pdf)\n\n### Kommentierter Lösungsweg\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- read_csv2(\"datasets/statistik/Datensatz_novanimal_Uebung_Statistik4.2.csv\")\n\n# sieht euch die Verteilung zwischen Mensagänger und Selbstverpfleger an\n# sind nicht gleichmässig verteilt, bei der Vorhersage müssen wir das berücksichtigen\ntable(df$mensa)\n## \n##   0   1 \n## 282 786\ndf |> count(mensa) # alternativ\n## # A tibble: 2 × 2\n##   mensa     n\n##   <dbl> <int>\n## 1     0   282\n## 2     1   786\n\n# definiert das logistische Modell und wendet es auf den Datensatz an\n\nmod0 <- glm(mensa ~ gender + member + age_groups + meat + umwelteinstellung,\n  data = df, binomial(\"logit\")\n)\nsummary.lm(mod0) # Umwelteinstellung scheint keinen Einfluss auf die\n## \n## Call:\n## glm(formula = mensa ~ gender + member + age_groups + meat + umwelteinstellung, \n##     family = binomial(\"logit\"), data = df)\n## \n## Weighted Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.6740 -0.8078  0.3712  0.5867  1.2379 \n## \n## Coefficients:\n##                              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                  -0.18889    0.40225  -0.470 0.638750    \n## genderMann                    0.71017    0.16018   4.434 1.02e-05 ***\n## memberStudent/in             -0.63072    0.29442  -2.142 0.032404 *  \n## age_groups26- bis 34-jaehrig  1.09429    0.19574   5.591 2.88e-08 ***\n## age_groups35- bis 49-jaehrig  1.75379    0.45968   3.815 0.000144 ***\n## age_groups50- bis 64-jaehrig  2.43530    0.78923   3.086 0.002083 ** \n## meat                          0.19945    0.05055   3.945 8.49e-05 ***\n## umwelteinstellung             0.19334    0.18688   1.035 0.301107    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.009 on 1060 degrees of freedom\n## Multiple R-squared:  0.004042,\tAdjusted R-squared:  -0.002536 \n## F-statistic: 0.6145 on 7 and 1060 DF,  p-value: 0.7443\n# Verpflegung zu haben, gegeben die Daten\n\n# neues Modell ohne Umwelteinstellung\nmod1 <- update(mod0, ~ . -umwelteinstellung)\nsummary.lm(mod1)\n## \n## Call:\n## glm(formula = mensa ~ gender + member + age_groups + meat, family = binomial(\"logit\"), \n##     data = df)\n## \n## Weighted Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.0117 -0.8060  0.3584  0.6100  1.2407 \n## \n## Coefficients:\n##                              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                   0.03212    0.34053   0.094 0.924860    \n## genderMann                    0.69697    0.15951   4.369 1.37e-05 ***\n## memberStudent/in             -0.64418    0.29426  -2.189 0.028806 *  \n## age_groups26- bis 34-jaehrig  1.11651    0.19458   5.738 1.25e-08 ***\n## age_groups35- bis 49-jaehrig  1.77409    0.45947   3.861 0.000120 ***\n## age_groups50- bis 64-jaehrig  2.44683    0.78953   3.099 0.001992 ** \n## meat                          0.18070    0.04709   3.837 0.000132 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.01 on 1061 degrees of freedom\n## Multiple R-squared:  0.003998,\tAdjusted R-squared:  -0.001635 \n## F-statistic: 0.7098 on 6 and 1061 DF,  p-value: 0.6418\n\n# Modeldiagnostik (wenn nicht signifikant, dann OK)\n1 - pchisq(mod1$deviance, mod1$df.resid) # Ok\n## [1] 0.4509591\n\n# Modellgüte (pseudo-R²)\n1 - (mod1$dev / mod1$null) # eher kleines pseudo-R2, deckt sich mit dem R-Squared aus dem obigen output summary.lm()\n## [1] 0.1354244\n\n# Konfusionsmatrix vom  Datensatz\n# Model Vorhersage\n# hier ein anderes Beispiel:\npredicted <- predict(mod1, df, type = \"response\")\n\n# erzeugt eine Tabelle mit den beobachteten\n# Mensagänger/Selbstverpfleger und den Vorhersagen des Modells\nkm <- table(predicted > 0.5, df$mensa)\n# alles was höher/grosser ist als 50% ist\n# kommt in die Kategorie Mensagänger\n\n# anpassung der namen\ndimnames(km) <- list(\n  c(\"Modell Selbstverpfleger\", \"Modell Mensagänger\"),\n  c(\"Daten Selbstverpfleger\", \"Daten Mensagänger\")\n)\nkm\n##                         Daten Selbstverpfleger Daten Mensagänger\n## Modell Selbstverpfleger                     87                59\n## Modell Mensagänger                         195               727\n\n#############\n### reminder: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62\n#############\n\n# TP = true positive: you predicted positive and it’s true; hier Vorhersage\n# Mensagänger stimmt also (727)\n\n# TN = true negative: you predicted negative and it’s true, hier Vorhersage der\n# Selbstverpfleger stimmt (87)\n\n# FP = false positive (fehler 1. art, auch Spezifizität genannt) you predicted\n# and it’s false. hier Modell sagt Mensagänger vorher\n# (obwohl in Realität Selbstverpfleger) (195)\n\n# FN = false negative (fehler 2. art, auch Sensitivität genannt),\n# you predicted negative and it’s false. hier Modell sagt Selbtverpfleger vorher\n# (obwohl in Realität Mensagänger) (59)\n\n\n# es scheint, dass das Modell häufig einen alpha Fehler macht, d.h.\n# das Modell weist keine hohe Spezifizität auf: konkret werden viele Mensagänger als\n# Selbstverpfleger vorhergesagt resp. klassifiziert. Dafür gibt es mehere Gründe:\n\n# 1) die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger\n# Selbstverpfleger als Mensgänger im Datensatz\n\n# 2) nicht adäquates Modell z.B. link mit probit zeigt besserer fit\n\n# 3) Overfitting: wurde hier nicht berücksichtigt, in einem Paper/Arbeit\n# müsste noch einen Validierungstest gemacht werden z.B. test-train\n# Cross-Validation oder k fold Cross-Validation\n\n# kalkuliert die Missklassifizierungsrate\nmf <- 1 - sum(diag(km) / sum(km)) # ist mit knapp 23 %  eher hoch\nmf\n## [1] 0.2378277\n\n# kleiner exkurs: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/\n# col wise proportion, da diese die \"Realität\" darstellt\nkm_prop <- prop.table(km, 2)\n\n# specificity = a / (a+c) => ability of a test to correctly\nspec = km_prop[1] / (km_prop[1] + km_prop[2])\nspec\n## [1] 0.3085106\n\n# sensitivity = d / (b+d) => Sensitivity is the ability of a\nsens = km_prop[4] / (km_prop[3] + km_prop[4])\nsens\n## [1] 0.9249364\n```\n:::\n\n\n### Methode\n\nIn der Aufgabe war es das Ziel zu schauen, ob wir einen potenziellen Besuch eines Mensagasts vorhersagen können und zwar in Abhängigkeit von den sozioökonomischen Variablen, wahrgenommene Fleischkonsum und der Umwelteinstellung. Die Kriteriumsvariable \"Mensa\" weist eine binäre Verteilung auf: Deshalb rechnen wir eine multiple logistische Regression mit den Prädiktoren “Alter”, “Geschlecht”, “Hochschulzugehörigkeit”, \"Fleischkonsum\" und \"Umwelteinstellung. Mehr Informationen zu den logistischen Regressionen findet ihr im Buch von Crawley (2015) oder auch im Buch von Gareth (2016).\n\n### Ergebnisse\n\n::: {.cell}\n::: {.cell-output-display}\n|                        | Daten Selbstverpfleger| Daten Mensagänger|\n|:-----------------------|----------------------:|-----------------:|\n|Modell Selbstverpfleger |                     87|                59|\n|Modell Mensagänger      |                    195|               727|\n\n\n\nKonfusionsmatrix\n:::\n:::\n\n\nDer Output des logistischen Models mit der Linkfunktin \"logit\" sagt und, dass das Modell nicht gut zu den Daten passt, d.h. mit dem Modell (gegeben die Daten) können wir nur schlecht vorhersagen, ob eine Person zukünftig sich in der Mensa verpflegt oder ihr Mittagessen selber mitnimmt. Hinweise dafür geben das kleine pseudo-R2 (14%) als auch die hohe Missklassifizierungsrate (24%): bei genauerer Betrachtung fällt auf, dass das Modell häufig einen alpha-Fehler begeht, d.h. unser Modell sagt zu viele Mensagänger vorher, obwohl diese in Realität Selbstverpfleger sind. \nEs gibt verschiedene Gründe für diesen schlechten Modelfit:\n\n* die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger Selbstverpfleger als Mensgänger im Datensatz (26% vs. 74%)\n* die Prädiktorvariablen sind alle entweder kategorial oder ordinal: dies kann dazu führen, dass das Model keinen guten fit zu den Daten erzielt \n\n**Fazit**: Es sollte nach einem weiteren adäquateren Modell gesucht werden: insbesondere ein Modell, welches einen mit ordinalen Prädiktorvariablen umgehen kann: \n\n- eine bessere Link-Funktion für das GLM suchen z.B. probit \n- [polynomiale Kontraste](https://stats.stackexchange.com/questions/195246/how-to-handle-ordinal-categorical-variable-as-independent-variable)\n- Smooth Splines [hier](https://www.frontiersin.org/articles/10.3389/fams.2017.00015/full)\n- multinomiale Regression z.M. nnet::mulitom() [hier](https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/) \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}