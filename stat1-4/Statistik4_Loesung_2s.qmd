---
date: 2022-11-08
lesson: Stat4
thema: Komplexere Regressionsmethoden
index: 4
format:
  html:
    code-tools:
      source: true
---

# Stat4: Lösung 4.2S

- Download dieses Lösungsscript via "\</\>Code" (oben rechts)

## Musterlösung Übung 4.2S: Multiple logistische Regression (SozWis)

- **Lese-Empfehlung** Kapitel 6 von [Manny Gimond]( https://mgimond.github.io/Stats-in-R/Logistic.html)
- **Lese-Empfehlung** Kapitel 4 von [Gareth (2016)](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)
- **Lese-Empfehlung** Vorlesungsfolien von Oscar Torres-Reyna [Princeton University](https://www.princeton.edu/~otorres/LogitR101.pdf)

### Kommentierter Lösungsweg
```{r}
#| echo: false
#| results: hide

library(dplyr)
library(readr)
library(ggplot2)

# für Informationen zu den einzelnen Variablen, siehe https://zenodo.org/record/3554884/files/2020_ZHAW_vonRickenbach_Variablen_cleaned_recoded_survey_dataset_anonym_NOVANIMAL.pdf?download=1

## definiert mytheme für ggplot2 (verwendet dabei theme_classic())
mytheme <- 
  theme_classic() + 
  theme(
    axis.line = element_line(color = "black"), 
    axis.text = element_text(size = 20, color = "black"), 
    axis.title = element_text(size = 20, color = "black"), 
    axis.ticks = element_line(size = 1, color = "black"), 
    axis.ticks.length = unit(.5, "cm")
    )
```

```{r}
df <- read_csv2("datasets/statistik/Datensatz_novanimal_Uebung_Statistik4.2.csv")

#  sieht euch die Verteilung zwischen Mensagänger und Selbstverpfleger an
# sind nicht gleichmässig verteilt, bei der Vorhersage müssen wir das berücksichtigen
table(df$mensa) 
df |> count(mensa) # alternativ

# definiert das logistische Modell und wendet es auf den Datensatz an

mod0 <-glm(mensa ~ gender + member + age_groups + meat + umwelteinstellung, 
           data = df, binomial("logit"))
summary.lm(mod0) # Umwelteinstellung scheint keinen Einfluss auf die 
# Verpflegung zu haben, gegeben die Daten

# neues Modell ohne Umwelteinstellung
mod1 <- update(mod0, ~. -umwelteinstellung)
summary.lm(mod1)

# Modeldiagnostik (wenn nicht signifikant, dann OK)
1 - pchisq(mod1$deviance, mod1$df.resid) # Ok

#Modellgüte (pseudo-R²)
1 - (mod1$dev / mod1$null) # eher kleines pseudo-R2, deckt sich mit dem R-Squared aus dem obigen output summary.lm()

# Konfusionsmatrix vom  Datensatz
# Model Vorhersage
# hier ein anderes Beispiel: 
predicted <- predict(mod1, df, type = "response")

# erzeugt eine Tabelle mit den beobachteten
# Mensagänger/Selbstverpfleger und den Vorhersagen des Modells
km <- table(predicted > 0.5, df$mensa) 
# alles was höher/grosser ist als 50% ist 
# kommt in die Kategorie Mensagänger

# anpassung der namen
dimnames(km) <- list(
  c("Modell Selbstverpfleger", "Modell Mensagänger"),
  c("Daten Selbstverpfleger", "Daten Mensagänger"))
km

#############
### reminder: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62
#############

#TP = true positive: you predicted positive and it’s true; hier Vorhersage 
# Mensagänger stimmt also (727)

#TN = true negative: you predicted negative and it’s true, hier Vorhersage der 
# Selbstverpfleger stimmt (87)

#FP = false positive (fehler 1. art, auch Spezifizität genannt) you predicted 
# and it’s false. hier Modell sagt Mensagänger vorher 
# (obwohl in Realität Selbstverpfleger) (195)

#FN = false negative (fehler 2. art, auch Sensitivität genannt), 
# you predicted negative and it’s false. hier Modell sagt Selbtverpfleger vorher 
# (obwohl in Realität Mensagänger) (59)


# es scheint, dass das Modell häufig einen alpha Fehler macht, d.h.  
# das Modell weist keine hohe Spezifizität auf: konkret werden viele Mensagänger als 
# Selbstverpfleger vorhergesagt resp. klassifiziert. Dafür gibt es mehere Gründe: 

#1) die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger
# Selbstverpfleger als Mensgänger im Datensatz 
 
#2) nicht adäquates Modell z.B. link mit probit zeigt besserer fit

#3) Overfitting: wurde hier nicht berücksichtigt, in einem Paper/Arbeit 
# müsste noch einen Validierungstest gemacht werden z.B. test-train 
# Cross-Validation oder k fold Cross-Validation 

# kalkuliert die Missklassifizierungsrate 
mf <- 1-sum(diag(km)/sum(km)) # ist mit knapp 23 %  eher hoch
mf

# kleiner exkurs: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/
# col wise proportion, da diese die "Realität" darstellt
km_prop <- prop.table(km,2)

# specificity = a / (a+c) => ability of a test to correctly 
spec = km_prop[1] / (km_prop[1] + km_prop[2])
spec

# sensitivity = d / (b+d) => Sensitivity is the ability of a 
sens = km_prop[4] / (km_prop[3] + km_prop[4])
sens
```

### Methode

In der Aufgabe war es das Ziel zu schauen, ob wir einen potenziellen Besuch eines Mensagasts vorhersagen können und zwar in Abhängigkeit von den sozioökonomischen Variablen, wahrgenommene Fleischkonsum und der Umwelteinstellung. Die Kriteriumsvariable "Mensa" weist eine binäre Verteilung auf: Deshalb rechnen wir eine multiple logistische Regression mit den Prädiktoren “Alter”, “Geschlecht”, “Hochschulzugehörigkeit”, "Fleischkonsum" und "Umwelteinstellung. Mehr Informationen zu den logistischen Regressionen findet ihr im Buch von Crawley (2015) oder auch im Buch von Gareth (2016).

### Ergebnisse
```{r}

#| echo: false
#| fig.cap: Konfusionsmatrix
knitr::kable(km)
```

Der Output des logistischen Models mit der Linkfunktin "logit" sagt und, dass das Modell nicht gut zu den Daten passt, d.h. mit dem Modell (gegeben die Daten) können wir nur schlecht vorhersagen, ob eine Person zukünftig sich in der Mensa verpflegt oder ihr Mittagessen selber mitnimmt. Hinweise dafür geben das kleine pseudo-R2 (14%) als auch die hohe Missklassifizierungsrate (24%): bei genauerer Betrachtung fällt auf, dass das Modell häufig einen alpha-Fehler begeht, d.h. unser Modell sagt zu viele Mensagänger vorher, obwohl diese in Realität Selbstverpfleger sind. 
Es gibt verschiedene Gründe für diesen schlechten Modelfit:

* die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger Selbstverpfleger als Mensgänger im Datensatz (26% vs. 74%)
* die Prädiktorvariablen sind alle entweder kategorial oder ordinal: dies kann dazu führen, dass das Model keinen guten fit zu den Daten erzielt 

**Fazit**: Es sollte nach einem weiteren adäquateren Modell gesucht werden: insbesondere ein Modell, welches einen mit ordinalen Prädiktorvariablen umgehen kann: 

- eine bessere Link-Funktion für das GLM suchen z.B. probit 
- [polynomiale Kontraste](https://stats.stackexchange.com/questions/195246/how-to-handle-ordinal-categorical-variable-as-independent-variable)
- Smooth Splines [hier](https://www.frontiersin.org/articles/10.3389/fams.2017.00015/full)
- multinomiale Regression z.M. nnet::mulitom() [hier](https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/) 
