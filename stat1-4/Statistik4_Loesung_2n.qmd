---
date: 2022-11-08
lesson: Stat4
thema: Komplexere Regressionsmethoden
index: 3
format:
  html:
    code-tools:
      source: true
---

# Stat4: Lösung 4.2N

- Download dieses Lösungsscript via "\</\>Code" (oben rechts)
- [Lösungstext als Download](Statistik_Loesung_4.2N.pdf)

## Musterlösung Aufgabe 4.2N: Multiple logistische Regression

```{r}
polis <- read.csv("datasets/statistik/polis.csv")
polis

str(polis)
summary(polis)
```

Man erkennt, dass polis 19 Beobachtungen von drei Parametern enthält, wobei ISLAND ein Faktor mit den Inselnamen ist, während RATIO metrisch ist und PA nur 0 oder 1 enthält. Prädiktorvariable ist RATIO, abhängige Variable PA, mithin ist das korrekte statistische Verfahren eine logistische Regression (GLM).

```{r}
# Explorative Datenanalyse
boxplot(polis$RATIO)
```

Der Boxplot  zeigt zwei starke Ausreisser, ist also etwas rechtsschief. Da es sich aber um die unabhängige Variable handelt, muss uns das nicht weiter stören.

```{r}
# Definition des logistischen Modells
glm.1 <- glm(PA~RATIO, family = "binomial", data = polis)
summary (glm.1)
```

Modell ist signifikant (p-Wert in Zeile RATIO ist < 0.05). Jetzt müssen wir noch prüfen, ob es auch valide ist:

```{r}
# Modelldiagnostik für das gewählte Modell (wenn nicht signifikant, dann OK)
1 - pchisq(glm.1$deviance, glm.1$df.resid)

# Visuelle Inspektion der Linearität
library(car)
crPlots(glm.1, ask = F)
```

Beide Aspekte sind OK, d.h. der Test war nicht signifikant und die pinkfarbene Linie liegt fast auf der theoretischen Linie (blau gestrichelt).

Jetzt brauchen wir noch die Modellgüte (Pseudo-R2):

```{r}
# Modellgüte (pseudo-R²)
1 - (glm.1$dev / glm.1$null)
```

Um zu unser Modell zu interpretieren müssen wir noch in Betracht ziehen, dass wir nicht die Vorkommenswahrscheinlichkeit selbst, sondern logit (Vorkommenswahrscheinlichkeit) modelliert haben. Unser Ergebnis (die beiden Parameterschätzungen von oben, also 3.6061 und -0.2196) muss also zunächst in etwas Interpretierbares übersetzt werden:

```{r}
# Steilheit der Beziehung in Modellen mit nur einem Parameter
exp(glm.1$coef[2])
```

< 1, d. h. Vorkommenswahrscheinlichkeit sinkt mit zunehmender Isolation.

```{r}
# LD50 für 1-Parameter-Modelle (hier also x-Werte, bei der 50% der Inseln besiedelt sind)
-glm.1$coef[1] / glm.1$coef[2]
```

Am besten stellen wir auch unsere Funktionsgleichung dar. Dazu müssen wir das „Rohergebnis“ (mit P = Vorkommenswahrscheinlichkeit)

ln (P/ (1- P)) = 3.606 – 0.220 RATIO

so umformen, dass wir links nur P stehen haben:

P = exp (3.606 – 0.220 RATIO) / (1 + exp (3.606 – 0.220 RATIO))

Das ist also unsere vorhergesagte Regressionsfunktion, die wir in einem letzten Schritt auch noch visualisieren können (und sollten):

```{r}
# Ergebnisplots
par(mfrow = c(1, 1))

xs <- seq(0, 70, l = 1000)
glm.predict <- predict(glm.1, type = "response", se = T, newdata = data.frame(RATIO=xs))

plot(PA~RATIO, data = polis, xlab = "Umfang-Flächen-Verhältnis", ylab = "Vorkommenswahrscheinlichkeit", pch = 16, col = "red")
     points(glm.predict$fit ~ xs,type="l")
     lines(glm.predict$fit + glm.predict$se.fit ~ xs, type = "l", lty = 2)
     lines(glm.predict$fit - glm.predict$se.fit ~ xs, type = "l", lty = 2)
```
